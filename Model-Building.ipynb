{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yashd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yashd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yashd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load the reviews and labels\n",
    "# 1 for positive reviews and 0 for negative reviews\n",
    "reviews = []\n",
    "labels = []\n",
    "path=\"aclImdb/train\"\n",
    "for label_type in [\"pos\", \"neg\"]:\n",
    "    dir_path = os.path.join(path, label_type)\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(dir_path, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(1 if label_type == \"pos\" else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Convert the reviews and labels to numpy arrays\n",
    "reviews = np.array(reviews)\n",
    "labels = np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    12500\n1    12500\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking balance of dataset\n",
    "pd.Series(labels).value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Define a function to perform text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub('<[^>]*>', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "\n",
    "    #Lemmatize and remove stopwords\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_text=' '.join(lemmatizer.lemmatize(word) for word in cleaned_text.split()\n",
    "                                                        if word not in stop_words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Preprocess the movie reviews\n",
    "cleaned_reviews = []\n",
    "for review in reviews:\n",
    "    cleaned_review = preprocess_text(review)\n",
    "    cleaned_reviews.append(cleaned_review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "train_reviews, test_reviews, train_labels, test_labels = train_test_split(cleaned_reviews, labels, test_size=0.15, random_state=42, shuffle=True, stratify=labels)\n",
    "train_reviews, val_reviews, train_labels, val_labels = train_test_split(train_reviews, train_labels, test_size=0.15, random_state=42, shuffle=True, stratify=train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing ML models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(),TfidfTransformer())\n",
    "\n",
    "X_train = pipeline.fit_transform(train_reviews)\n",
    "X_val = pipeline.transform(val_reviews)\n",
    "X_test = pipeline.transform(test_reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import time\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(kernel=\"linear\"),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Time taken: 6.968690395355225\n",
      "----------------------------------------------------\n",
      "Logistic Regression\n",
      "Time taken: 20.587644577026367\n",
      "----------------------------------------------------\n",
      "SVM\n",
      "Time taken: 1976.6532769203186\n",
      "----------------------------------------------------\n",
      "Random Forest\n",
      "Time taken: 4465.19069314003\n",
      "----------------------------------------------------\n",
      "XGBoost Classifier\n",
      "Time taken: 5181.1491086483\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model_list=[]\n",
    "\n",
    "# Define the parameter grid for each model\n",
    "nb_param_grid = {'alpha': [0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "lr_param_grid = {'C': [0.1, 1, 10, 100],\n",
    "                 'penalty': ['l1', 'l2']}\n",
    "\n",
    "svm_param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "rf_param_grid = {'n_estimators': [50, 100, 200, 300],\n",
    "                 'max_depth': [None, 5, 10, 20],\n",
    "                 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "xgb_param_grid = {'n_estimators': [50, 100, 200, 300],\n",
    "                  'max_depth': [3, 5, 10],\n",
    "                  'learning_rate': [0.1, 0.01, 0.001]}\n",
    "\n",
    "# Define the parameter grids for all models in a dictionary\n",
    "param_grids = {'MultinomialNB': nb_param_grid,\n",
    "               'Logistic Regression': lr_param_grid,\n",
    "               'SVM': svm_param_grid,\n",
    "               'Random Forest': rf_param_grid,\n",
    "               'XGBoost Classifier': xgb_param_grid}\n",
    "\n",
    "for model_name,param in param_grids.items():\n",
    "\n",
    "    start = time.time()\n",
    "    algo = models[model_name]\n",
    "    grid_search = GridSearchCV(estimator=algo,param_grid=param,cv=5,n_jobs=-1,scoring='accuracy')\n",
    "    grid_search.fit(X_train,train_labels)\n",
    "    best_para = grid_search.best_params_\n",
    "    algo.set_params(**best_para)\n",
    "    algo.fit(X_train,train_labels)\n",
    "    y_pred = algo.predict(X_val)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"Time taken: {end-start}\")\n",
    "    model_list.append([model_name,accuracy_score(val_labels,y_pred),precision_score(val_labels,y_pred),recall_score(val_labels,y_pred),f1_score(val_labels,y_pred),best_para])\n",
    "    print(\"----------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "            Model name  Accuracy  Precision    Recall  f1-score  \\\n0        MultinomialNB  0.860100   0.865140  0.853199  0.859128   \n1  Logistic Regression  0.896801   0.888275  0.907779  0.897921   \n2                  SVM  0.898996   0.890663  0.909661  0.900062   \n3        Random Forest  0.861669   0.868842  0.851945  0.860310   \n4   XGBoost Classifier  0.863237   0.856527  0.872647  0.864512   \n\n                                     Best Parameters  \n0                                     {'alpha': 0.1}  \n1                         {'C': 10, 'penalty': 'l2'}  \n2                                           {'C': 1}  \n3  {'max_depth': None, 'min_samples_split': 5, 'n...  \n4  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model name</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>f1-score</th>\n      <th>Best Parameters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MultinomialNB</td>\n      <td>0.860100</td>\n      <td>0.865140</td>\n      <td>0.853199</td>\n      <td>0.859128</td>\n      <td>{'alpha': 0.1}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Logistic Regression</td>\n      <td>0.896801</td>\n      <td>0.888275</td>\n      <td>0.907779</td>\n      <td>0.897921</td>\n      <td>{'C': 10, 'penalty': 'l2'}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVM</td>\n      <td>0.898996</td>\n      <td>0.890663</td>\n      <td>0.909661</td>\n      <td>0.900062</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>0.861669</td>\n      <td>0.868842</td>\n      <td>0.851945</td>\n      <td>0.860310</td>\n      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost Classifier</td>\n      <td>0.863237</td>\n      <td>0.856527</td>\n      <td>0.872647</td>\n      <td>0.864512</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df = pd.DataFrame(data=model_list,columns=['Model name','Accuracy','Precision','Recall','f1-score','Best Parameters'])\n",
    "models_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choosing Logistic Regression for our analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=10,penalty='l2')\n",
    "model.fit(X_train,train_labels)\n",
    "prediction = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      1825\n",
      "           1       0.89      0.87      0.88      1925\n",
      "\n",
      "    accuracy                           0.88      3750\n",
      "   macro avg       0.88      0.88      0.88      3750\n",
      "weighted avg       0.88      0.88      0.88      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(prediction,test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open('ml_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "with open('preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}